# âš ï¸ æ–°å¢: åŠ è½½å¤–éƒ¨çš„å…‰è°±å…ˆéªŒä¼˜åŒ–æ¨¡å— (åŸ `train_optimize.py` ä¸­çš„å‡½æ•°)
#################################################################
# Rec:RGBå›¾åƒçš„MSEï¼ˆå€¼è¶Šå°è¶Šå¥½ï¼‰ã€‚é€šå¸¸è®¤ä¸º <0.05 å°±æ˜¯è‚‰çœ¼çœ‹ä¸å‡ºå·®å¼‚çš„æ°´å¹³
# Ang:å…‰ç…§ä¼°è®¡çš„è§’åº¦è¯¯å·®ï¼ˆå•ä½ä¸ºåº¦ï¼‰ã€‚
# Loss:
################################################################
from train_optimize import run_stage_1_optimization

import torch
import os
import sys
from torch.utils.data import DataLoader
from config import SystemConfig
from models.pipeline import MSIReproductionPipeline
from datasets.data_synthesis import SyntheticSpectralDataset
from models.losses import PaperLoss


def train():
    # ==========================
    # 1. åŸºç¡€é…ç½®ä¸è®¾å¤‡åˆå§‹åŒ–
    # ==========================
    config = SystemConfig()
    # è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„è®¾å¤‡å‚æ•°ï¼Œé¿å…ç¡¬ç¼–ç 
    # å¼ºåˆ¶æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯: ä»£ç è¦æ±‚å¿…é¡»åœ¨ GPU ä¸Šè¿è¡Œï¼Œä½†æœªæ£€æµ‹åˆ° CUDA è®¾å¤‡ï¼")
        sys.exit(1)  # ç›´æ¥é€€å‡ºç¨‹åº

    # å¼ºåˆ¶æŒ‡å®šè®¾å¤‡ä¸º cuda
    device = torch.device("cuda")
    print(f"âœ… å·²é”å®š GPU: {torch.cuda.get_device_name(0)}")
    print(f"   æ˜¾å­˜çŠ¶æ€: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB used")
    print(f"ğŸ“‹å½“å‰é…ç½®: Batch={config.model.batch_size}, LR={config.model.lr}, Epochs={config.model.max_epochs}")

    # # ==========================
    # # 2. æ•°æ®å‡†å¤‡
    # # ==========================
    # HSI_DATA_PATH = config.dataset.train_data_root  # ä»é…ç½®è¯»å–è·¯å¾„ï¼Œè€Œéç¡¬ç¼–ç 
    # if not os.path.exists(HSI_DATA_PATH) or len(os.listdir(HSI_DATA_PATH)) == 0:
    #     print(f"âŒ é”™è¯¯: åœ¨ {HSI_DATA_PATH} æ‰¾ä¸åˆ°æ•°æ®é›†ï¼")
    #     print("ğŸ’¡ è¯·å°† .h5 æ–‡ä»¶æ”¾å…¥æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæˆ–ä¿®æ”¹ config.py ä¸­çš„ train_data_root")
    #     return
    #
    # print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®é›†: {HSI_DATA_PATH}")
    # dataset = SyntheticSpectralDataset(hsi_data_root=HSI_DATA_PATH, config=config)
    # dataloader = DataLoader(
    #     dataset,
    #     batch_size=config.model.batch_size,  # ä»é…ç½®è¯»å– batch_size
    #     shuffle=True,
    #     num_workers=os.cpu_count() // 2,  # è‡ªåŠ¨æ ¹æ®CPUæ ¸å¿ƒæ•°è®¾ç½® workers
    #     pin_memory=True if torch.cuda.is_available() else False  # åŠ é€ŸGPUä¼ è¾“
    # )
    # print(f"âœ… æ•°æ®åŠ è½½å®Œæ¯•ï¼Œé¢„è®¡æ¯ä¸ª epoch æœ‰ {len(dataloader)} ä¸ª Batch")
    # ==========================
    # 2. æ•°æ®å‡†å¤‡
    # ==========================
    # âœ… ä¿®æ”¹ç‚¹ï¼šä» config.dataset ä¸­è¯»å–è·¯å¾„
    hsi_data_root = config.dataset.train_data_root

    # ç®€å•çš„è·¯å¾„æ£€æŸ¥
    if not os.path.exists(hsi_data_root):
        print(f"âŒ é”™è¯¯: æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ -> {hsi_data_root}")
        print("ğŸ’¡ è¯·åœ¨ config.py ä¸­ä¿®æ”¹ dataset.train_data_root")
        return

    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®é›†: {hsi_data_root}")
    dataset = SyntheticSpectralDataset(hsi_data_root=hsi_data_root, config=config)

    # âœ… ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨ config.num_workers
    dataloader = DataLoader(
        dataset,
        batch_size=config.model.batch_size,
        shuffle=True,
        num_workers=config.num_workers,  # ç»Ÿä¸€ç”± config æ§åˆ¶
        pin_memory=(config.device == "cuda")  # GPUä¸‹å¼€å¯ pin_memory
    )
    print(f"âœ… æ•°æ®åŠ è½½å®Œæ¯•ï¼Œå…± {len(dataloader)} ä¸ª Batch")

    # ==========================
    # 3. è®ºæ–‡ Stage 1: å…‰è°±å…ˆéªŒä¼˜åŒ–
    # ==========================
    # è°ƒç”¨å¤–éƒ¨æ¨¡å—å®ç°çš„ Algorithm 1
    T_init, M_init = run_stage_1_optimization(config, hsi_data_root)

    # ==========================
    # 4. æ¨¡å‹ä¸ä¼˜åŒ–å™¨ (è®ºæ–‡ Stage 2)
    # ==========================
    model = MSIReproductionPipeline(
        config,
        initial_T=T_init,  # æ³¨å…¥ Stage 1 çš„ç‰©ç†å…ˆéªŒ
        initial_M=M_init
    ).to(device)

    model.train()  # å¼€å¯è®­ç»ƒæ¨¡å¼
    optimizer = torch.optim.Adam(model.parameters(), lr=config.model.lr)  # ä»é…ç½®è¯»å–å­¦ä¹ ç‡
    criterion = PaperLoss(
        lambda_ae=config.model.lambda_ae,  # ä»é…ç½®è¯»å–æŸå¤±æƒé‡ (è®ºæ–‡ Eq.6)
        lambda_rmse=config.model.lambda_rmse  # ä»é…ç½®è¯»å–æŸå¤±æƒé‡ (è®ºæ–‡ Eq.8)
    ).to(device)
    print(f"ğŸ”§ å·²åˆå§‹åŒ–æ¨¡å‹: {model.__class__.__name__}, æŸå¤±å‡½æ•°: {criterion.__class__.__name__}")

    # ==========================
    # 5. è®­ç»ƒå¾ªç¯ (Training Loop)
    # ==========================
    epochs = config.model.max_epochs  # ä»é…ç½®è¯»å–è®­ç»ƒè½®æ•°
    # æå‰åˆ›å»ºcheckpointç›®å½•
    os.makedirs("checkpoints", exist_ok=True)

    print(f"\nğŸ å¼€å§‹è®­ç»ƒï¼Œå…± {epochs} ä¸ª Epoch")
    for epoch in range(epochs):
        epoch_loss = 0.0
        # é‡ç½® batch æŸå¤±ç»Ÿè®¡
        total_rec_loss = 0.0
        total_ang_loss = 0.0

        for i, batch in enumerate(dataloader):
            # æ•°æ®é€å…¥è®¾å¤‡
            raw_msi = batch['input'].to(device)
            gt_rgb = batch['gt_rgb'].to(device)
            gt_L = batch['gt_L'].to(device)

            optimizer.zero_grad()
            # å‰å‘ä¼ æ’­ï¼Œä¸æ¨¡å‹æ¶æ„å¯¹é½
            pred_rgb, intermediates = model(raw_msi)

            # è®¡ç®—æŸå¤± (ä¸è®ºæ–‡å…¬å¼ (6)(7)(8) å®Œå…¨å¯¹é½)
            l_hat = intermediates['l_hat']
            loss, rec_val, ang_val = criterion(pred_rgb, gt_rgb, l_hat, gt_L)

            loss.backward()
            optimizer.step()

            # ç´¯ç§¯æŸå¤±æ•°æ®
            epoch_loss += loss.item()
            total_rec_loss += rec_val
            total_ang_loss += ang_val

            # æ¯ 10 ä¸ª batch æ‰“å°ä¸€æ¬¡è¿›åº¦
            if i % 10 == 0:
                print(
                    f"Epoch [{epoch + 1}/{epochs}] Step [{i}/{len(dataloader)}] "
                    f"Loss: {loss.item():.4f} (Rec: {rec_val:.4f}, Ang: {ang_val:.2f}Â°)"
                )

        # æ¯ä¸ª Epoch ç»“æŸåçš„ç»Ÿè®¡ä¸ä¿å­˜
        avg_loss = epoch_loss / len(dataloader)
        avg_rec = total_rec_loss / len(dataloader)
        avg_ang = total_ang_loss / len(dataloader)

        print(
            f"==== Epoch {epoch + 1} ç»“æŸ | "
            f"å¹³å‡ Loss: {avg_loss:.4f}, å¹³å‡ RecLoss: {avg_rec:.4f}, å¹³å‡ AngLoss: {avg_ang:.2f}Â° ===="
        )

        # ä¿å­˜ checkpointï¼Œæ ¹æ®é…ç½®çš„é¢‘ç‡
        if (epoch + 1) % config.model.save_freq == 0:
            save_path = f"checkpoints/model_epoch_{epoch + 1}.pth"
            torch.save(model.state_dict(), save_path)
            print(f"ğŸ’¾ æƒé‡å·²ä¿å­˜è‡³: {save_path}")

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_path = "checkpoints/best_model.pth"
    torch.save(model.state_dict(), final_path)
    print(f"\nğŸ‰ è®­ç»ƒå…¨éƒ¨å®Œæˆï¼æœ€ç»ˆæ¨¡å‹ä¿å­˜è‡³: {final_path}")
    print(f"ğŸ‘‰ ç°åœ¨å¯ä»¥è¿è¡Œ run_inference.py æµ‹è¯•æ•ˆæœå•¦ï¼")


if __name__ == "__main__":
    train()