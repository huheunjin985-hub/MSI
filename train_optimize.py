# train_optimize.py
import torch
import torch.optim as optim
import os
from torch.utils.data import DataLoader
from datasets.data_synthesis import SyntheticSpectralDataset


# ------------------------------------------------------------------
# ğŸ”¥ ä¿®æ”¹è¯´æ˜:
# 1. åˆ é™¤äº† EnterpriseTrainer ç±» (å› ä¸ºè®­ç»ƒé€»è¾‘ç°åœ¨åœ¨ train.py é‡Œ)
# 2. å¢åŠ äº†â€œç¼“å­˜â€æœºåˆ¶ï¼šè¿è¡Œè¿‡ä¸€æ¬¡åä¼šè‡ªåŠ¨ä¿å­˜ï¼Œä¸‹æ¬¡ç›´æ¥åŠ è½½ï¼Œä¸ç”¨é‡è·‘
# ------------------------------------------------------------------

def run_stage_1_optimization(config, hsi_data_path):
    """
    å®ç°è®ºæ–‡ Algorithm 1: Spectral Prior-guided Optimization (Stage 1)

    è¯¥å‡½æ•°ä¼šè¢« train.py è°ƒç”¨ã€‚
    å¦‚æœæ£€æµ‹åˆ°å·²ç»ä¼˜åŒ–è¿‡çš„å‚æ•°æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½è¿”å›ï¼›å¦åˆ™å¼€å§‹ä¼˜åŒ–ã€‚
    """

    # å®šä¹‰ä¿å­˜è·¯å¾„ï¼Œé¿å…é‡å¤è®¡ç®—
    save_dir = "checkpoints/priors"
    save_path = os.path.join(save_dir, "spectral_prior.pth")

    # --- 1. æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¼“å­˜ ---
    if os.path.exists(save_path):
        print(f"âš¡ [Stage 1] å‘ç°å·²ä¼˜åŒ–çš„ç‰©ç†å…ˆéªŒ: {save_path}")
        print("   ğŸ‘‰ ç›´æ¥åŠ è½½ï¼Œè·³è¿‡ä¼˜åŒ–æ­¥éª¤...")
        data = torch.load(save_path, map_location=config.device)
        return data['t_rgb'], data['m_static']

    # --- 2. å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œå¼€å§‹ä¼˜åŒ– ---
    print(f"ğŸš€ [Stage 1] æœªæ‰¾åˆ°ç¼“å­˜ï¼Œå¼€å§‹è¿è¡Œå…‰è°±å…ˆéªŒä¼˜åŒ– (Optimization for T_RGB & M)...")

    device = config.device

    # æ•°æ®é›†å‡†å¤‡ (åªéœ€è¦å°‘é‡æ•°æ®å³å¯æ”¶æ•›)
    dataset = SyntheticSpectralDataset(hsi_data_root=hsi_data_path, config=config)
    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)

    # å‚æ•°åˆå§‹åŒ–
    C = config.camera.num_channels
    # T_RGB: (C, 3)
    T_RGB = torch.nn.Parameter(torch.randn(C, 3, device=device) * 0.1, requires_grad=True)
    # M: (3, 3) åˆå§‹åŒ–ä¸ºå•ä½çŸ©é˜µ
    M = torch.nn.Parameter(torch.eye(3, device=device), requires_grad=True)

    optimizer = optim.Adam([T_RGB, M], lr=0.01)

    # åªéœ€è¦è·‘ 500 æ¬¡è¿­ä»£å³å¯
    num_steps = 500
    iter_loader = iter(dataloader)

    for step in range(num_steps):
        try:
            batch = next(iter_loader)
        except StopIteration:
            iter_loader = iter(dataloader)
            batch = next(iter_loader)

        # æ•°æ®é€å…¥è®¾å¤‡
        input_msi = batch['input'].to(device)  # (B, C, H, W)
        gt_rgb = batch['gt_rgb'].to(device)  # (B, 3, H, W)
        gt_L = batch['gt_L'].to(device)  # (B, C)

        B, _, H, W = input_msi.shape

        # === æ ¸å¿ƒç‰©ç†å…¬å¼å®ç° (Eq. 4) ===
        # 1. å˜æ¢ç»´åº¦: (B, H, W, C)
        raw = input_msi.permute(0, 2, 3, 1)

        # 2. RGB Subspace Projection: I_MSI @ T_RGB
        proj_rgb = torch.matmul(raw, T_RGB)

        # 3. White Balancing: W = L @ T_RGB
        L_vec = gt_L.view(B, 1, 1, C)
        white_point = torch.matmul(L_vec, T_RGB)  # (B, 1, 1, 3)

        # Avoid division by zero
        wb_rgb = proj_rgb / (white_point + 1e-8)

        # 4. Color Correction: pred = wb @ M
        pred_linear = torch.matmul(wb_rgb, M)

        # 5. Gamma Correction (To sRGB)
        pred_srgb = torch.clamp(pred_linear, 0, 1) ** (1 / 2.2)

        # === Loss è®¡ç®— ===
        # Reconstruct Loss
        loss_rec = torch.nn.functional.mse_loss(pred_srgb.permute(0, 3, 1, 2), gt_rgb)

        # M Regularization (è¡Œå’Œä¸º1)
        row_sums = torch.sum(M, dim=1)
        loss_reg = torch.mean((row_sums - 1.0) ** 2)

        loss = loss_rec + 0.1 * loss_reg

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if step % 100 == 0:
            print(f"   Step [{step}/{num_steps}] Loss: {loss.item():.6f} (Rec: {loss_rec.item():.6f})")

    print("\nâœ… å…‰è°±å…ˆéªŒä¼˜åŒ–å®Œæˆï¼")

    # --- 3. ä¿å­˜ç»“æœåˆ°ç¡¬ç›˜ ---
    os.makedirs(save_dir, exist_ok=True)
    # Detach detachå¹¶è½¬åˆ°CPUä¿å­˜
    t_final = T_RGB.detach().cpu()
    m_final = M.detach().cpu()

    torch.save({
        't_rgb': t_final,
        'm_static': m_final
    }, save_path)
    print(f"ğŸ’¾ å‚æ•°å·²ä» GPU è½¬ç§»å¹¶ä¿å­˜è‡³: {save_path}")

    return t_final, m_final


if __name__ == "__main__":
    # å¦‚æœä½ æƒ³å•ç‹¬æµ‹è¯•è¿™ä¸ªæ–‡ä»¶ï¼Œä¹Ÿå¯ä»¥ç›´æ¥è¿è¡Œå®ƒ
    from config import SystemConfig

    cfg = SystemConfig()
    try:
        run_stage_1_optimization(cfg, "./data/KAIST")
    except Exception as e:
        print(f"æµ‹è¯•è¿è¡Œéœ€ç¡®ä¿æ•°æ®è·¯å¾„æ­£ç¡®: {e}")