import torch
import os
import sys  # ğŸ”¥ æ–°å¢ sys ç”¨äºæŠ¥é”™é€€å‡º
import numpy as np
from config import SystemConfig
from models import MSIReproductionPipeline
from utils import load_raw_file, save_srgb_image  # å‡è®¾å…¶ä»–å·¥å…·å‡½æ•°ä¸éœ€è¦å˜

# ==========================================
#      ã€åœ¨æ­¤å¤„ä¿®æ”¹ä½ çš„è¿è¡Œé…ç½®ã€‘
# ==========================================
# 1. è¾“å…¥æ–‡ä»¶è·¯å¾„
INPUT_PATH = "data/raw/sample_scene.raw"

# 2. è¾“å‡ºä¿å­˜ä½ç½®
OUTPUT_PATH = "data/output/result_gpu_fixed.png"

# 3. æƒé‡è·¯å¾„
WEIGHTS_PATH = "checkpoints/best_model.pth"

# 4. å›¾åƒå‚æ•°
IMG_WIDTH = 480
IMG_HEIGHT = 300
IMG_CHANNELS = 9
IMG_BIT_DEPTH = 12


# ==========================================

def run():
    print(f"--- MSI Color Reproduction Inference (GPU Mode) ---")

    # 1. å¼ºåˆ¶æ£€æŸ¥ GPU (ğŸ”¥ ä¿®æ”¹ç‚¹ 1)
    if not torch.cuda.is_available():
        print("âŒ ä¸¥é‡é”™è¯¯: æœªæ£€æµ‹åˆ° GPUï¼æ­¤ä»£ç å¼ºåˆ¶è¦æ±‚ CUDA ç¯å¢ƒã€‚")
        sys.exit(1)

    # å¼ºåˆ¶é”å®š GPU
    device = torch.device("cuda")
    print(f"âœ… å·²é”å®šè®¾å¤‡: {torch.cuda.get_device_name(0)}")

    # 2. æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(INPUT_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_PATH}")
        return  # å»ºè®®ç›´æ¥è¿”å›ï¼Œä¸è¦å†ç”Ÿæˆå‡æ•°æ®å¹²æ‰°åˆ¤æ–­äº†

    # 3. åŠ è½½é…ç½®
    config = SystemConfig()
    config.camera.input_width = IMG_WIDTH
    config.camera.input_height = IMG_HEIGHT
    config.camera.num_channels = IMG_CHANNELS
    config.camera.bit_depth = IMG_BIT_DEPTH
    config.device = "cuda"  # ğŸ”¥ æ˜¾å¼åŒæ­¥é…ç½®

    # 4. åˆå§‹åŒ–æ¨¡å‹å¹¶ä¸Šå¡
    print("â³ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model = MSIReproductionPipeline(config).to(device)
    model.eval()  # å¼€å¯è¯„ä¼°æ¨¡å¼

    # 5. åŠ è½½æƒé‡
    if WEIGHTS_PATH and os.path.exists(WEIGHTS_PATH):
        # map_location ç¡®ä¿æƒé‡ç›´æ¥åŠ è½½åˆ° GPU
        state_dict = torch.load(WEIGHTS_PATH, map_location=device)
        model.load_state_dict(state_dict)
        print(f"âœ… æˆåŠŸåŠ è½½æƒé‡: {WEIGHTS_PATH}")
    else:
        print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æƒé‡æ–‡ä»¶ï¼Œè¾“å‡ºå°†æ˜¯éšæœºå™ªå£°ï¼")

    # 6. è¯»å–æ•°æ® (ç¡®ä¿ .to(device))
    try:
        input_tensor = load_raw_file(
            INPUT_PATH,
            IMG_WIDTH,
            IMG_HEIGHT,
            IMG_CHANNELS,
            IMG_BIT_DEPTH
        ).to(device)  # ğŸ”¥ æ•°æ®ç›´æ¥ä¸Š GPU

        # å¢åŠ ä¸€ä¸ªç»´åº¦ (Batch Size) å¦‚æœ load_raw_file æ²¡æœ‰åŠ çš„è¯
        if input_tensor.dim() == 3:
            input_tensor = input_tensor.unsqueeze(0)

    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
        return

    # 7. æ¨ç† (å¼€å¯ no_grad èŠ‚çœæ˜¾å­˜)
    print("ğŸš€ æ­£åœ¨æ¨ç†...")
    with torch.no_grad():
        srgb_out, _ = model(input_tensor)

        # ==========================================================
        #  ã€å…³é”®ä¿®å¤æ­¥éª¤ã€‘
        # ==========================================================
        print(">>> æ­£åœ¨åº”ç”¨è‰²å½©ä¿®å¤...")

        # ğŸ”¥ ä¿®æ”¹ç‚¹ 2: ä¿®æ­£é€šé“é¡ºåº BGR -> RGB
        # åŸä»£ç  [0, 1, 2] æ˜¯æ²¡å˜çš„ï¼Œå¿…é¡»æ”¹æˆ [2, 1, 0] æ‰èƒ½äº¤æ¢çº¢è“é€šé“
        # srgb_out = srgb_out[:, [2, 1, 0], :, :]
        # print("  âœ… å·²æ‰§è¡Œ BGR -> RGB é€šé“äº¤æ¢")

        # ğŸ”¥ ä¿®æ”¹ç‚¹ 3: Gamma æ ¡æ­£ä¸æˆªæ–­
        # å…ˆé™åˆ¶èŒƒå›´åœ¨ 0-1 ä¹‹é—´ï¼Œé˜²æ­¢è´Ÿæ•°å¯¼è‡´ pow æŠ¥é”™
        srgb_out = torch.clamp(srgb_out, 0.0, 1.0)

        # Gamma 2.2 æ ¡æ­£ (Linear -> sRGB)
        # å¦‚æœå‡ºæ¥çš„å›¾ç‰‡å¾ˆç™½/é›¾è’™è’™ï¼Œè¯´æ˜æ¨¡å‹å·²ç»å­¦åˆ°äº†Gammaï¼Œè¯·æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
        srgb_out = torch.pow(srgb_out, 1.0 / 2.2)
        print("  âœ… Gamma (2.2) æ ¡æ­£å·²åº”ç”¨")
        # ==========================================================

    # 8. ä¿å­˜
    # å¦‚æœ save_srgb_image å‡½æ•°é‡ŒåŒ…å« .cpu() è½¬æ¢ï¼Œè¿™é‡Œå°±ä¸ç”¨ç®¡ï¼›
    # å¦‚æœæŠ¥é”™ï¼Œå¯èƒ½éœ€è¦å…ˆ srgb_out.cpu()
    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
    save_srgb_image(srgb_out, OUTPUT_PATH)  # ç¡®ä¿ utils é‡Œå¤„ç†äº† tensor

    print(f"âœ… ä¿å­˜æˆåŠŸ: {OUTPUT_PATH}")


if __name__ == "__main__":
    run()